{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised machine learning: Introduction and regularization \n",
    "## Binary classification with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import pickle\n",
    "\n",
    "## nltk imports\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "## sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "## print mult things\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## random\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to process text\n",
    "def processtext(one_str, stop_list):\n",
    "    \n",
    "    ## remove stopwords\n",
    "    no_stop = [tok for tok in wordpunct_tokenize(one_str)\n",
    "              if tok not in stop_list]\n",
    "    \n",
    "    \n",
    "    processed_string = \" \".join([porter.stem(i.lower()) \n",
    "                        for i in no_stop if \n",
    "                        i.lower().isalpha() and len(i) >=3])\n",
    "    return(processed_string)\n",
    "\n",
    "## function to create dtm\n",
    "def create_dtm(list_of_strings, metadata):\n",
    "    vectorizer = CountVectorizer(lowercase = True)\n",
    "    dtm_sparse = vectorizer.fit_transform(list_of_strings)\n",
    "    dtm_dense_named = pd.DataFrame(dtm_sparse.todense(), columns=vectorizer.get_feature_names_out())\n",
    "    dtm_dense_named_withid = pd.concat([metadata.reset_index(), dtm_dense_named], axis = 1)\n",
    "    return(dtm_dense_named_withid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Load labeled yelp data in `public_data` and run below code\n",
    "\n",
    "**Note**: make sure to change your path if you need to; if you're having trouble loading the `pkl`, try running on jupyter hub since it may be a python versioning issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have trouble loading these data (kernel dies due to memory issues), try sampling down to 5000 or 1000 rows\n",
    "yelp = pd.read_pickle(\"../public_data/yelp_forML.pkl\") #.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess data to create dtm\n",
    "porter = PorterStemmer()\n",
    "list_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "yelp['process_text'] = [processtext(one_review, stop_list = list_stopwords) \n",
    "                        for one_review in yelp['raw_text']]\n",
    "\n",
    "yelp_dtm = create_dtm(yelp['process_text'], yelp[['metadata_label', 'metadata_rowid',\n",
    "                                                 'process_text', 'raw_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>metadata_label</th>\n",
       "      <th>metadata_rowid</th>\n",
       "      <th>process_text</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaa</th>\n",
       "      <th>aaaaaaaaaaaaaaand</th>\n",
       "      <th>aaaaaaaaaaaaahhhhhhhhhhh</th>\n",
       "      <th>aaaaand</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorba</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuch</th>\n",
       "      <th>zuchinni</th>\n",
       "      <th>zum</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zuppa</th>\n",
       "      <th>zwei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfortun frustrat goldberg patient repeat experi mani doctor nyc good doctor terribl staff seem staff simpli never answer phone usual take hour repeat call get answer who time want deal run problem mani doctor get you offic worker patient medic need anyon answer phone incomprehens work aggrav regret feel give goldberg star</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>been go goldberg year think one patient start mhmg great year realli big pictur former gyn markoff found fibroid explor option patient understand judg ask right question veri thorough want kept loop everi aspect medic health life</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>know goldberg like move arizona let tell stay away doctor offic go johnson left goldberg took johnson left care doctor interest pay come medic refil everi month give refil could less patient financi situat tri get day mail away pharmaci prescript guy joke and make matter even wors offic staff incompet time call offic put voic mail one ever answer return call both adult children husband decid leav practic experienc frustrat the entir offic attitud like favor give break stay away doc practic you deserv better realli need never felt compel write bad review anyon met pathet excus doctor money</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>write review give head see doctor the offic staff administr unprofession left messag multipl peopl regard bill one ever call back hound get answer bill nsecond import make sure insur go cover goldberg visit blood work recommend get physic knew student told got physic done later found health insur pay prevent visit receiv bill blood work pay bill student cash flow current time believ doctor give head make sure insur would cover work necessari strictli prevent the offic anyth help cover bill addit offic staff said onu make sure insur cover visit frustrat situat</td>\n",
       "      <td>I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\n\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an $800.00 bill for the blood work. I can't pay for my bill because I'm a student and don't have any cash flow at this current time. I can't believe the Doctor wouldn't give me a heads up to make sure my insurance would cover work that wasn't necessary and was strictly preventative. The office can't do anything to help me cover the bill. In addition, the office staff said the onus is on me to make sure my insurance covers visits. Frustrating situation!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>all food great but best thing wing their wing simpli fantast the wet cajun best popular also like season salt wing wing night monday wednesday night whole wing nthe dine area nice veri famili friendli the bar nice well thi place truli yinzer dream pittsburgh dad would love place</td>\n",
       "      <td>All the food is great here. But the best thing they have is their wings. Their wings are simply fantastic!!  The \\\"Wet Cajun\\\" are by the best &amp; most popular.  I also like the seasoned salt wings.  Wing Night is Monday &amp; Wednesday night, $0.75 whole wings!\\n\\nThe dining area is nice. Very family friendly! The bar is very nice is well.  This place is truly a Yinzer's dream!!  \\\"Pittsburgh Dad\\\" would love this place n'at!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14995</td>\n",
       "      <td>0</td>\n",
       "      <td>14995</td>\n",
       "      <td>fabric hype theme restaur chain arizona intent select nearli locat insuffici park insuffici build size accommod custom onc lengthi waitlist along small crowd other want think wow happen place nbut pain stop the hostess strict unreason seat rule exampl seat parti top tabl peopl park car not even second later seat parti last remain top tabl then cours miss peopl walk right wait minut next avail top tabl great polici oregano nthi self style chicago theme restaur offer deep dish pizza quick point long wait pizza like wait long time get seat vast major pizza sale thin crust not bad reput great chicago pizza exactli chicago thin crust nwall mural entertain self deprec shirt worn staff food averag menu quit decor non whole though hype littl way substanc</td>\n",
       "      <td>Fabricated hype is the theme for this restaurant chain in Arizona - they intentionally select (nearly) all locations with insufficient parking and insufficient building size to accommodate their customers.  Once you're on the lengthy waitlist along with a small crowd of others, they want you to think.... wow, this is a happening place!\\n\\nBut the pain doesn't stop here.  The hostess has strict but unreasonable seating rules.  Example: she wouldn't seat my party of 4 at a 4 top table because 2 people were parking the car.  Not even 30 seconds later, she seats a party of 2 at that last remaining 4 top table.  Then, of course, my 2 missing people walk right up and we have to wait 25 minutes for the next available 4 top table.  Great policy, Oreganos!\\n\\nThis self-styled Chicago theme restaurant offers deep dish pizza, but they're quick to point out how long the wait is for the pizza (likely after you've waited a long time just to get a seat) and so the vast majority of their pizza sales are thin crust.  Not bad, but the reputation for great Chicago pizza isn't exactly \\\"Chicago thin crust\\\".\\n\\nWall murals are entertaining, as are the self-deprecating T-shirts worn by the staff.  Food is very average, and the menu is quite decorative.\\n\\nOn the whole though, it's all hype and little in way of substance.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>14996</td>\n",
       "      <td>1</td>\n",
       "      <td>14996</td>\n",
       "      <td>never wait tabl locat servic alway great the first time ate overwhelm menu mani option sound great thi authent italian restaur like make classic dish twist the portion huge price reason the food pretti good tri boom dip appet forget leav room pizooki heavenli</td>\n",
       "      <td>I have never had to wait for a table at this location and the service is always great. The first time I ate here I was so overwhelmed by the menu there are so many options and all of them sound great. This isn't an authentic Italian restaurant but I like how they make all the classic dishes with a twist . The portions are huge and the prices are reasonable. The food here is pretty good try the Boom Dip as an appetizer and don't forget to leave room for the Pizookie its heavenly.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14997</td>\n",
       "      <td>1</td>\n",
       "      <td>14997</td>\n",
       "      <td>what say never wrong tri frequent mostli local own restaur oregano call sometim love uniqu salad select fact get choos small larg the pizza crust perfect thin ness spice right spend fortun and get leftov nnow servic never wait drink refil hunt server extra napkin send back cold pizza alway get upbeat person servic server mysef realli make happi rememb everi server name definit ask trish great experi</td>\n",
       "      <td>What can I say...they never do me wrong!  I try to frequent mostly local owned restaurants, but Oregano's just calls to me sometimes.  I love the unique salad selection and the fact that I get to choose small or large.  The pizza crust is the perfect thin-ness, the spices just right, I don't have to spend a fortune AND I get leftovers!  \\nNow the service...again, I have never had to wait for drink refills, hunt down my server for extra napkins, or send back a cold pizza.  I always get upbeat and personable service and as a server mysef, this really makes me happy.  \\nI don't remember every server's name I have had there, but definitely ask for Trish for great experience!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>14998</td>\n",
       "      <td>0</td>\n",
       "      <td>14998</td>\n",
       "      <td>oregano vile baffl crowd follow seem will loiter degre heat hour everyth tast someon accid salt shaker kitchen bland bore dehydr thank</td>\n",
       "      <td>Oregano's, you are vile, and I am baffled by your crowds of followers who seem willing to loiter about in 115 degree heat for over an hour for you. Everything tastes as if someone had an accident with the salt shaker in the kitchen. Bland, boring, and dehydrating. No thanks.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999</td>\n",
       "      <td>0</td>\n",
       "      <td>14999</td>\n",
       "      <td>oregano anywher know food like like food like find much salti realli worth long wait nthi particular joint alway busi point overcrowd lunch dinner servic good outdoor seat despit decent server wait either sit quit wait pizza takeout good option npark problem restaur enough spillov local neighborhood care peopl drink tend drive without even look leav valuabl visibl car even the area around camelback experi lot smash grab theft even assault awar surround good neighborhood buzz well fed peopl easi mark nthe neg review think lot better support local own place instead chain and live neighborhood found oregano unrecept work neighborhood resid overcom park litter problem increas crime associ problem</td>\n",
       "      <td>If you've been to any Oregano's anywhere, you know what the food here is like. If you like the food, you like it. I find it much too salty and not really worth the long wait.\\n\\nThis particular joint is always busy to the point of overcrowding for lunch and dinner. Service is good and they have outdoor seating. Despite decent servers you will have a wait, either to sit down at all, or quite a wait for your pizza. Takeout is a good option. \\n\\nParking is a problem because the restaurant doesn't have enough, so there is spillover into the local neighborhood. BE CAREFUL: People who have been drinking tend to drive out of there without even looking. Do not leave any valuables visible in your car, not even a CD. The area around 10th St and Camelback experiences a lot of smash and grab theft and even assault, so be aware of your surroundings. It's a good neighborhood, but buzzed, well-fed people are easy marks.\\n\\nThe negative review is because I think you can do a LOT better while supporting a locally owned place instead of a chain. And because I live in this neighborhood, and we have found Oregano's most unreceptive to working with the neighborhood residents to overcome parking and litter problems, and an increase in crime associated with these problems.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 23442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  metadata_label  metadata_rowid  \\\n",
       "0          0               0               0   \n",
       "1          1               1               1   \n",
       "2          2               0               2   \n",
       "3          3               0               3   \n",
       "4          4               1               4   \n",
       "...      ...             ...             ...   \n",
       "14995  14995               0           14995   \n",
       "14996  14996               1           14996   \n",
       "14997  14997               1           14997   \n",
       "14998  14998               0           14998   \n",
       "14999  14999               0           14999   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               process_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                      unfortun frustrat goldberg patient repeat experi mani doctor nyc good doctor terribl staff seem staff simpli never answer phone usual take hour repeat call get answer who time want deal run problem mani doctor get you offic worker patient medic need anyon answer phone incomprehens work aggrav regret feel give goldberg star   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     been go goldberg year think one patient start mhmg great year realli big pictur former gyn markoff found fibroid explor option patient understand judg ask right question veri thorough want kept loop everi aspect medic health life   \n",
       "2                                                                                                                                                                       know goldberg like move arizona let tell stay away doctor offic go johnson left goldberg took johnson left care doctor interest pay come medic refil everi month give refil could less patient financi situat tri get day mail away pharmaci prescript guy joke and make matter even wors offic staff incompet time call offic put voic mail one ever answer return call both adult children husband decid leav practic experienc frustrat the entir offic attitud like favor give break stay away doc practic you deserv better realli need never felt compel write bad review anyon met pathet excus doctor money   \n",
       "3                                                                                                                                                                                                     write review give head see doctor the offic staff administr unprofession left messag multipl peopl regard bill one ever call back hound get answer bill nsecond import make sure insur go cover goldberg visit blood work recommend get physic knew student told got physic done later found health insur pay prevent visit receiv bill blood work pay bill student cash flow current time believ doctor give head make sure insur would cover work necessari strictli prevent the offic anyth help cover bill addit offic staff said onu make sure insur cover visit frustrat situat   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   all food great but best thing wing their wing simpli fantast the wet cajun best popular also like season salt wing wing night monday wednesday night whole wing nthe dine area nice veri famili friendli the bar nice well thi place truli yinzer dream pittsburgh dad would love place   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "14995  fabric hype theme restaur chain arizona intent select nearli locat insuffici park insuffici build size accommod custom onc lengthi waitlist along small crowd other want think wow happen place nbut pain stop the hostess strict unreason seat rule exampl seat parti top tabl peopl park car not even second later seat parti last remain top tabl then cours miss peopl walk right wait minut next avail top tabl great polici oregano nthi self style chicago theme restaur offer deep dish pizza quick point long wait pizza like wait long time get seat vast major pizza sale thin crust not bad reput great chicago pizza exactli chicago thin crust nwall mural entertain self deprec shirt worn staff food averag menu quit decor non whole though hype littl way substanc   \n",
       "14996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   never wait tabl locat servic alway great the first time ate overwhelm menu mani option sound great thi authent italian restaur like make classic dish twist the portion huge price reason the food pretti good tri boom dip appet forget leav room pizooki heavenli   \n",
       "14997                                                                                                                                                                                                                                                                                                                                                                    what say never wrong tri frequent mostli local own restaur oregano call sometim love uniqu salad select fact get choos small larg the pizza crust perfect thin ness spice right spend fortun and get leftov nnow servic never wait drink refil hunt server extra napkin send back cold pizza alway get upbeat person servic server mysef realli make happi rememb everi server name definit ask trish great experi   \n",
       "14998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                oregano vile baffl crowd follow seem will loiter degre heat hour everyth tast someon accid salt shaker kitchen bland bore dehydr thank   \n",
       "14999                                                         oregano anywher know food like like food like find much salti realli worth long wait nthi particular joint alway busi point overcrowd lunch dinner servic good outdoor seat despit decent server wait either sit quit wait pizza takeout good option npark problem restaur enough spillov local neighborhood care peopl drink tend drive without even look leav valuabl visibl car even the area around camelback experi lot smash grab theft even assault awar surround good neighborhood buzz well fed peopl easi mark nthe neg review think lot better support local own place instead chain and live neighborhood found oregano unrecept work neighborhood resid overcom park litter problem increas crime associ problem   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        raw_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.   \n",
       "2                                                                                                                                                                                        I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.   \n",
       "3                                                                                                                                                                                                                                                                                     I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\n\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an $800.00 bill for the blood work. I can't pay for my bill because I'm a student and don't have any cash flow at this current time. I can't believe the Doctor wouldn't give me a heads up to make sure my insurance would cover work that wasn't necessary and was strictly preventative. The office can't do anything to help me cover the bill. In addition, the office staff said the onus is on me to make sure my insurance covers visits. Frustrating situation!   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      All the food is great here. But the best thing they have is their wings. Their wings are simply fantastic!!  The \\\"Wet Cajun\\\" are by the best & most popular.  I also like the seasoned salt wings.  Wing Night is Monday & Wednesday night, $0.75 whole wings!\\n\\nThe dining area is nice. Very family friendly! The bar is very nice is well.  This place is truly a Yinzer's dream!!  \\\"Pittsburgh Dad\\\" would love this place n'at!!   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "14995  Fabricated hype is the theme for this restaurant chain in Arizona - they intentionally select (nearly) all locations with insufficient parking and insufficient building size to accommodate their customers.  Once you're on the lengthy waitlist along with a small crowd of others, they want you to think.... wow, this is a happening place!\\n\\nBut the pain doesn't stop here.  The hostess has strict but unreasonable seating rules.  Example: she wouldn't seat my party of 4 at a 4 top table because 2 people were parking the car.  Not even 30 seconds later, she seats a party of 2 at that last remaining 4 top table.  Then, of course, my 2 missing people walk right up and we have to wait 25 minutes for the next available 4 top table.  Great policy, Oreganos!\\n\\nThis self-styled Chicago theme restaurant offers deep dish pizza, but they're quick to point out how long the wait is for the pizza (likely after you've waited a long time just to get a seat) and so the vast majority of their pizza sales are thin crust.  Not bad, but the reputation for great Chicago pizza isn't exactly \\\"Chicago thin crust\\\".\\n\\nWall murals are entertaining, as are the self-deprecating T-shirts worn by the staff.  Food is very average, and the menu is quite decorative.\\n\\nOn the whole though, it's all hype and little in way of substance.   \n",
       "14996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I have never had to wait for a table at this location and the service is always great. The first time I ate here I was so overwhelmed by the menu there are so many options and all of them sound great. This isn't an authentic Italian restaurant but I like how they make all the classic dishes with a twist . The portions are huge and the prices are reasonable. The food here is pretty good try the Boom Dip as an appetizer and don't forget to leave room for the Pizookie its heavenly.   \n",
       "14997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What can I say...they never do me wrong!  I try to frequent mostly local owned restaurants, but Oregano's just calls to me sometimes.  I love the unique salad selection and the fact that I get to choose small or large.  The pizza crust is the perfect thin-ness, the spices just right, I don't have to spend a fortune AND I get leftovers!  \\nNow the service...again, I have never had to wait for drink refills, hunt down my server for extra napkins, or send back a cold pizza.  I always get upbeat and personable service and as a server mysef, this really makes me happy.  \\nI don't remember every server's name I have had there, but definitely ask for Trish for great experience!   \n",
       "14998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Oregano's, you are vile, and I am baffled by your crowds of followers who seem willing to loiter about in 115 degree heat for over an hour for you. Everything tastes as if someone had an accident with the salt shaker in the kitchen. Bland, boring, and dehydrating. No thanks.   \n",
       "14999                                                     If you've been to any Oregano's anywhere, you know what the food here is like. If you like the food, you like it. I find it much too salty and not really worth the long wait.\\n\\nThis particular joint is always busy to the point of overcrowding for lunch and dinner. Service is good and they have outdoor seating. Despite decent servers you will have a wait, either to sit down at all, or quite a wait for your pizza. Takeout is a good option. \\n\\nParking is a problem because the restaurant doesn't have enough, so there is spillover into the local neighborhood. BE CAREFUL: People who have been drinking tend to drive out of there without even looking. Do not leave any valuables visible in your car, not even a CD. The area around 10th St and Camelback experiences a lot of smash and grab theft and even assault, so be aware of your surroundings. It's a good neighborhood, but buzzed, well-fed people are easy marks.\\n\\nThe negative review is because I think you can do a LOT better while supporting a locally owned place instead of a chain. And because I live in this neighborhood, and we have found Oregano's most unreceptive to working with the neighborhood residents to overcome parking and litter problems, and an increase in crime associated with these problems.   \n",
       "\n",
       "       aaa  aaaaaa  aaaaaaaaaaaaaaand  aaaaaaaaaaaaahhhhhhhhhhh  aaaaand  ...  \\\n",
       "0        0       0                  0                         0        0  ...   \n",
       "1        0       0                  0                         0        0  ...   \n",
       "2        0       0                  0                         0        0  ...   \n",
       "3        0       0                  0                         0        0  ...   \n",
       "4        0       0                  0                         0        0  ...   \n",
       "...    ...     ...                ...                       ...      ...  ...   \n",
       "14995    0       0                  0                         0        0  ...   \n",
       "14996    0       0                  0                         0        0  ...   \n",
       "14997    0       0                  0                         0        0  ...   \n",
       "14998    0       0                  0                         0        0  ...   \n",
       "14999    0       0                  0                         0        0  ...   \n",
       "\n",
       "       zoom  zorba  zucchini  zuch  zuchinni  zum  zuma  zumba  zuppa  zwei  \n",
       "0         0      0         0     0         0    0     0      0      0     0  \n",
       "1         0      0         0     0         0    0     0      0      0     0  \n",
       "2         0      0         0     0         0    0     0      0      0     0  \n",
       "3         0      0         0     0         0    0     0      0      0     0  \n",
       "4         0      0         0     0         0    0     0      0      0     0  \n",
       "...     ...    ...       ...   ...       ...  ...   ...    ...    ...   ...  \n",
       "14995     0      0         0     0         0    0     0      0      0     0  \n",
       "14996     0      0         0     0         0    0     0      0      0     0  \n",
       "14997     0      0         0     0         0    0     0      0      0     0  \n",
       "14998     0      0         0     0         0    0     0      0      0     0  \n",
       "14999     0      0         0     0         0    0     0      0      0     0  \n",
       "\n",
       "[15000 rows x 23442 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split into features, labels, and split into training/hold out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Split into X (features or id metadata) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_dtm[[col for col in yelp_dtm.columns if col not in ['metadata_label',\n",
    "                                                            'index']]].copy()\n",
    "y = yelp_dtm[['metadata_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 23439)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking dimensionality\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "assert X.shape[0] == y.shape[0]\n",
    "assert y.shape[1] == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 using automatic function to create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### using built-in function  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 221)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 using more manual approach to create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### more manually: useful when we want more control\n",
    "### over the ids (eg clustering or time ordering)\n",
    "### or if we want to go back to matrix before preprocessing\n",
    "nrows_train = round(X.shape[0]*0.8)\n",
    "nrows_test = X.shape[0] - nrows_train\n",
    "random.seed(221)\n",
    "train_ids = random.sample(list(set(X['metadata_rowid'])), nrows_train)\n",
    "\n",
    "def my_split(X, y, \n",
    "             train_ids, \n",
    "             id_col):\n",
    "    \n",
    "    ## get test ids\n",
    "    test_ids = set(X[id_col]).difference(train_ids)\n",
    "    \n",
    "    ## split\n",
    "    X_train_man = X[X[id_col].isin(train_ids)].copy()\n",
    "    X_test_man = X[X[id_col].isin(test_ids)].copy()\n",
    "    y_train_man = y[y.index.isin(train_ids)].iloc[:, 0].to_numpy()\n",
    "    y_test_man = y[y.index.isin(test_ids)].iloc[:, 0].to_numpy()\n",
    "    \n",
    "    ## return\n",
    "    return(X_train_man, X_test_man, y_train_man, y_test_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_man, X_test_man, y_train_man, y_test_man = my_split(X, y,\n",
    "                                                            train_ids, \n",
    "                                                            id_col = 'metadata_rowid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Estimate models with hardcoded parameters: logistic regression with L1 regularization (Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Estimate model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_feat = ['metadata_rowid', 'raw_text', 'process_text']\n",
    "logit_lasso = LogisticRegression(penalty = \"l1\",max_iter=100, \n",
    "             C = 0.01, solver='liblinear')\n",
    "logit_lasso.fit(X_train_man[[col for col in X_train.columns if col not in \n",
    "                   non_feat]], y_train_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generate predictions in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit_lasso.predict(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])\n",
    "y_predprob = logit_lasso.predict_proba(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64281388, 0.35718612],\n",
       "       [0.69708125, 0.30291875],\n",
       "       [0.06361857, 0.93638143],\n",
       "       [0.72129942, 0.27870058],\n",
       "       [0.50410806, 0.49589194]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the results \n",
    "y_pred[0:5]\n",
    "y_predprob[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Clean up predictions and calculate error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_binary</th>\n",
       "      <th>y_pred_continuous</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>0.240211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>1</td>\n",
       "      <td>0.698138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1</td>\n",
       "      <td>0.790660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0</td>\n",
       "      <td>0.448079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.432694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>1</td>\n",
       "      <td>0.679520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.681769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.519438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>0</td>\n",
       "      <td>0.192980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred_binary  y_pred_continuous  y_true\n",
       "656               0           0.240211       0\n",
       "825               1           0.698138       1\n",
       "1641              1           0.790660       1\n",
       "2249              1           0.535241       1\n",
       "1080              0           0.448079       0\n",
       "2490              0           0.432694       1\n",
       "2857              1           0.679520       1\n",
       "1160              1           0.681769       1\n",
       "1061              1           0.519438       0\n",
       "2255              0           0.192980       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make into a dataframe\n",
    "y_pred_df = pd.DataFrame({'y_pred_binary': y_pred,\n",
    "                         'y_pred_continuous': [one_prob[1] \n",
    "                                            for one_prob in y_predprob],\n",
    "                         'y_true': y_test_man})\n",
    "y_pred_df.sample(n = 10, random_state = 4484)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TN</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FN</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FP</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat     n\n",
       "0  TN  1320\n",
       "1  TP  1103\n",
       "2  FN   319\n",
       "3  FP   258"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is:-----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8104335047759"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is:---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7756680731364276"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precision as tp / tp+fp \n",
    "error_cond = [(y_pred_df['y_true'] == 1) & (y_pred_df['y_pred_binary'] == 1),\n",
    "             (y_pred_df['y_true'] == 1) & (y_pred_df['y_pred_binary'] == 0),\n",
    "              (y_pred_df['y_true'] == 0) & (y_pred_df['y_pred_binary'] == 0)]\n",
    "\n",
    "error_codeto = [\"TP\", \"FN\", \"TN\"]\n",
    "\n",
    "y_pred_df['error_cat'] = np.select(error_cond, error_codeto, default = \"FP\")\n",
    "y_error = y_pred_df.error_cat.value_counts().reset_index().copy()\n",
    "y_error.columns = ['cat', 'n']\n",
    "y_error\n",
    "\n",
    "### precision\n",
    "print(\"Precision is:-----------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FP\", 'n'].iloc[0])\n",
    "\n",
    "### recall\n",
    "print(\"Recall is:---------------\")\n",
    "y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0]/(y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                    y_error.loc[y_error.cat == \"FN\", 'n'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Interpret the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>0.839776</td>\n",
       "      <td>delici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170</th>\n",
       "      <td>0.780820</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11104</th>\n",
       "      <td>0.614076</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.445008</td>\n",
       "      <td>amaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>0.399783</td>\n",
       "      <td>excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20768</th>\n",
       "      <td>-0.303358</td>\n",
       "      <td>terribl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21101</th>\n",
       "      <td>-0.309612</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>-0.362104</td>\n",
       "      <td>noth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>-0.381813</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23108</th>\n",
       "      <td>-0.487947</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23436 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef feature_name\n",
       "5009   0.839776       delici\n",
       "8170   0.780820        great\n",
       "11104  0.614076         love\n",
       "526    0.445008         amaz\n",
       "6510   0.399783        excel\n",
       "...         ...          ...\n",
       "20768 -0.303358      terribl\n",
       "21101 -0.309612         told\n",
       "14032 -0.362104         noth\n",
       "1251  -0.381813          bad\n",
       "23108 -0.487947        worst\n",
       "\n",
       "[23436 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xc/0mc4v93x1sl61jqqdrj91f7c0000gn/T/ipykernel_66767/4204865.py:11: FutureWarning: The provided callable <function mean at 0x10fb7dbc0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delici</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>amaz</th>\n",
       "      <th>excel</th>\n",
       "      <th>best</th>\n",
       "      <th>favorit</th>\n",
       "      <th>friendli</th>\n",
       "      <th>definit</th>\n",
       "      <th>alway</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metadata_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026424</td>\n",
       "      <td>0.171178</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.103506</td>\n",
       "      <td>0.027713</td>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.113302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162248</td>\n",
       "      <td>0.557305</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.104529</td>\n",
       "      <td>0.093621</td>\n",
       "      <td>0.219691</td>\n",
       "      <td>0.116819</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0.142640</td>\n",
       "      <td>0.242613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  delici     great      love      amaz     excel      best  \\\n",
       "metadata_label                                                               \n",
       "0               0.026424  0.171178  0.085976  0.022944  0.018819  0.103506   \n",
       "1               0.162248  0.557305  0.284452  0.104529  0.093621  0.219691   \n",
       "\n",
       "                 favorit  friendli   definit     alway  \n",
       "metadata_label                                          \n",
       "0               0.027713  0.067672  0.059036  0.113302  \n",
       "1               0.116819  0.169014  0.142640  0.242613  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get top features\n",
    "las_coef = pd.DataFrame({'coef': logit_lasso.coef_[0],\n",
    "                         'feature_name': \n",
    "                        [col for col in X_train.columns if col not in non_feat]})\n",
    "las_coef.sort_values(by = 'coef', ascending = False)\n",
    "\n",
    "\n",
    "top_feat = las_coef.sort_values(by = 'coef', ascending = False)[0:10]\n",
    "top_feat_list = top_feat.feature_name.to_list()\n",
    "\n",
    "all_agg = [yelp_dtm.groupby(['metadata_label']).agg({one_feat: np.mean})\n",
    "for one_feat in top_feat_list]\n",
    "all_agg_df = pd.concat(all_agg, axis = 1)\n",
    "all_agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare performance across hyperparameters for logistic regression\n",
    "\n",
    "Would our logit model make more accurate predictions if we fed it different hyperpameters? Which hyperparameters would be the best? Let's find out.\n",
    "\n",
    "1. Define a function that:\n",
    "- takes in a cost parameter (*C*, the inverse of regularization strength)\n",
    "- trains a logistic regression model with L1 regularization (Lasso) and otherwise has the same parameters as above\n",
    "- fits the model on the training data\n",
    "- makes predictions and returns them as a DataFrame\n",
    "\n",
    "2. Use the function to get predictions for the list of *C* parameters below, then bind them into one DataFrame.\n",
    "\n",
    "3. Finally, score the precision for each model (each iteration of *C*) and show which model scores the best.\n",
    "\n",
    "**Hint**: To compute precision score, you can use:\n",
    "```python\n",
    "precision_score(\n",
    "    one_df['y_true'], one_df['y_pred'],\n",
    "    zero_division = 0) # silences warning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.000000e+00, 3.000025e+00, 2.000050e+00, 1.000075e+00,\n",
       "       1.000000e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provided set of hyperparameters on which to train and then compare performance\n",
    "c_list = np.linspace(4, 0.0001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_binary</th>\n",
       "      <th>y_pred_continuous</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.429954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1</td>\n",
       "      <td>0.955725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred_binary  y_pred_continuous  y_true\n",
       "0                 0           0.000768       0\n",
       "1                 0           0.045176       0\n",
       "2                 1           1.000000       1\n",
       "3                 0           0.000006       0\n",
       "4                 0           0.429954       0\n",
       "...             ...                ...     ...\n",
       "2995              0           0.000001       0\n",
       "2996              0           0.000897       0\n",
       "2997              0           0.000330       0\n",
       "2998              0           0.000039       0\n",
       "2999              1           0.955725       0\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your function code here\n",
    "non_feat = ['metadata_rowid', 'raw_text', 'process_text']\n",
    "\n",
    "def c_predicter(c_parameter):\n",
    "    logit_lasso = LogisticRegression(penalty = \"l1\",max_iter=100, \n",
    "             C = c_parameter, solver='liblinear')\n",
    "    logit_lasso.fit(X_train_man[[col for col in X_train.columns if col not in \n",
    "                   non_feat]], y_train_man)\n",
    "    y_pred = logit_lasso.predict(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])\n",
    "    y_predprob = logit_lasso.predict_proba(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])\n",
    "    y_pred_df = pd.DataFrame({'y_pred_binary': y_pred,\n",
    "                         'y_pred_continuous': [one_prob[1] \n",
    "                                            for one_prob in y_predprob],\n",
    "                         'y_true': y_test_man})\n",
    "    return y_pred_df\n",
    "\n",
    "\n",
    "c_predicter(c_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       y_pred_binary  y_pred_continuous  y_true  C_value\n",
      "0                  0           0.000784       0   4.0000\n",
      "1                  0           0.046116       0   4.0000\n",
      "2                  1           1.000000       1   4.0000\n",
      "3                  0           0.000006       0   4.0000\n",
      "4                  0           0.429683       0   4.0000\n",
      "...              ...                ...     ...      ...\n",
      "14995              0           0.500000       0   0.0001\n",
      "14996              0           0.500000       0   0.0001\n",
      "14997              0           0.500000       0   0.0001\n",
      "14998              0           0.500000       0   0.0001\n",
      "14999              0           0.500000       0   0.0001\n",
      "\n",
      "[15000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "for C_param in c_list:\n",
    "    current_predictions = c_predicter(C_param)\n",
    "    current_predictions['C_value'] = C_param\n",
    "    predictions_df = pd.concat([predictions_df, current_predictions], ignore_index=True)\n",
    "\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions for each C-value:\n",
      "C_value\n",
      "0.000100    0.000000\n",
      "1.000075    0.863136\n",
      "2.000050    0.861687\n",
      "3.000025    0.860977\n",
      "4.000000    0.860594\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# your code here to evaluate precision of each model\n",
    "\n",
    "def calculate_precision(predictions_df):\n",
    "    # Define error categories\n",
    "    error_cond = [\n",
    "        (predictions_df['y_true'] == 1) & (predictions_df['y_pred_binary'] == 1),\n",
    "        (predictions_df['y_true'] == 1) & (predictions_df['y_pred_binary'] == 0),\n",
    "        (predictions_df['y_true'] == 0) & (predictions_df['y_pred_binary'] == 0)\n",
    "    ]\n",
    "    error_codeto = [\"TP\", \"FN\", \"TN\"]\n",
    "    \n",
    "    # Assign error categories\n",
    "    predictions_df['error_cat'] = np.select(error_cond, error_codeto, default=\"FP\")\n",
    "    \n",
    "    # Count error categories\n",
    "    y_error = predictions_df['error_cat'].value_counts().reset_index().copy()\n",
    "    y_error.columns = ['cat', 'n']\n",
    "    \n",
    "    # Calculate precision\n",
    "    if 'TP' in y_error['cat'].values and 'FP' in y_error['cat'].values:\n",
    "        precision = y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] / (y_error.loc[y_error.cat == \"TP\", 'n'].iloc[0] +\n",
    "                                                                    y_error.loc[y_error.cat == \"FP\", 'n'].iloc[0])\n",
    "    else:\n",
    "        precision = 0  # Set precision to 0 if TP or FP doesn't exist\n",
    "    return precision\n",
    "\n",
    "grouped_df = predictions_df.groupby('C_value')\n",
    "\n",
    "# Calculate precision for each group\n",
    "precisions = grouped_df.apply(calculate_precision)\n",
    "\n",
    "# Display the precisions for each C-value\n",
    "print(\"Precisions for each C-value:\")\n",
    "print(precisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x177670b50>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Precision vs. C-value')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'C-value')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Precision Score')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the line graph\n",
    "plt.plot(precisions.index, precisions.values, marker='o', linestyle='-')\n",
    "plt.title('Precision vs. C-value')\n",
    "plt.xlabel('C-value')\n",
    "plt.ylabel('Precision Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3000, 13]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m predictions_df:\n\u001b[0;32m----> 3\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(f1_score(y_test_man, y))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[1;32m   1012\u001b[0m     y_true,\n\u001b[1;32m   1013\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1020\u001b[0m ):\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fbeta_score(\n\u001b[1;32m   1147\u001b[0m         y_true,\n\u001b[1;32m   1148\u001b[0m         y_pred,\n\u001b[1;32m   1149\u001b[0m         beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1150\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   1151\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m   1152\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m   1153\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1154\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[1;32m   1155\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[1;32m   1159\u001b[0m     y_true,\n\u001b[1;32m   1160\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1168\u001b[0m ):\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1288\u001b[0m         y_true,\n\u001b[1;32m   1289\u001b[0m         y_pred,\n\u001b[1;32m   1290\u001b[0m         beta\u001b[38;5;241m=\u001b[39mbeta,\n\u001b[1;32m   1291\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   1292\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m   1293\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m   1294\u001b[0m         warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-score\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m   1295\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1296\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[1;32m   1297\u001b[0m     )\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3000, 13]"
     ]
    }
   ],
   "source": [
    "# Example but won't work with this code\n",
    "results = []\n",
    "for y in predictions_df:\n",
    "    results.append(f1_score(y_test_man, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Activity \n",
    "\n",
    "- Read the documentation here to initialize a ridge regression (l2 penalty)- you can use the same cost parameter (C) and number of iterations as in the lasso example above: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- Fit the model on X_train_man, y_train_main \n",
    "- Generate binary and continuous predictions\n",
    "- Create a function that takes in a dataframe of binary predictions and true labels and manually calculates the $F_{1}$ score:\n",
    "\n",
    "$$F_{1} = 2 * \\dfrac{precision * recall}{precision + recall} = \\dfrac{TP}{TP + 0.5(FP + FN)}$$\n",
    "\n",
    "- Apply that function to calculate the F1 score for the decision tree and lasso (from above), and ridge regression (from the activity)\n",
    "- *Challenge exercise*: parametrize the model fitting with a function that takes in a classifier as an argument and returns coefficients or feature importances and certain eval metrics (eg precision, recall, and F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_ridge = LogisticRegression(penalty = \"l2\",max_iter=100, \n",
    "             C = 0.01, solver='liblinear')\n",
    "logit_ridge.fit(X_train_man[[col for col in X_train.columns if col not in \n",
    "                   non_feat]], y_train_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit_ridge.predict(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])\n",
    "y_predprob = logit_ridge.predict_proba(X_test_man[[col for col \n",
    "                in X_test_man.columns if col not in non_feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred_binary</th>\n",
       "      <th>y_pred_continuous</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>1</td>\n",
       "      <td>0.720484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1</td>\n",
       "      <td>0.847071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>1</td>\n",
       "      <td>0.704340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0</td>\n",
       "      <td>0.410711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>1</td>\n",
       "      <td>0.620160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>1</td>\n",
       "      <td>0.693145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1</td>\n",
       "      <td>0.712472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.575025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred_binary  y_pred_continuous  y_true\n",
       "656               0           0.087789       0\n",
       "825               1           0.720484       1\n",
       "1641              1           0.847071       1\n",
       "2249              1           0.704340       1\n",
       "1080              0           0.410711       0\n",
       "2490              1           0.620160       1\n",
       "2857              1           0.693145       1\n",
       "1160              1           0.712472       1\n",
       "1061              1           0.575025       0\n",
       "2255              0           0.100325       0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make into a dataframe\n",
    "y_pred_df = pd.DataFrame({'y_pred_binary': y_pred,\n",
    "                         'y_pred_continuous': [one_prob[1] \n",
    "                                            for one_prob in y_predprob],\n",
    "                         'y_true': y_test_man})\n",
    "y_pred_df.sample(n = 10, random_state = 4484)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8706866504008364"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8686868686868688"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_f1_score(df):\n",
    "    y_pred_binary = df['y_pred_binary']\n",
    "    y_true = df['y_true']\n",
    "    return f1_score(y_true, y_pred_binary)\n",
    "\n",
    "calculate_f1_score(y_pred_df)\n",
    "calculate_f1_score(predictions_df[predictions_df['C_value'] == 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
